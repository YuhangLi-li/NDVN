# NDVN
Luminance Domain Guided Low-light Image Enhancement 
In low-light conditions, images have poor contrast and noise due to lack of exposure, making it difficult for visual tasks to be performed on them. In fact, low-light images also have non-uniform brightness, such as nightlight, backlight and shadow occlusion. A common drawback of existing low-light enhancement methods is that they tend to increase the overall image brightness, which can result in overexposure of areas that are not originally low-light. Dark areas should be enhanced while overexposed areas should be suppressed. To address this problem, this paper proposes a novel Non-uniform Dark Vision Network--NDVN, which consists of two sub-networks. The Luminance Domain Network (LDN) uses the Direction-aware Spatial Context (DSC) and Feature Enhancement Module (FEM) to segment different light regions in the image and output the luminance domain mask. Guided by the luminance domain mask, the Light Enhancement Network (LEN) uses our proposed Cross-Domain Transformation Residual block (CDTR) to adaptively illuminate different illumination regions, while we introduce a new region loss function to constrain the LEN to better enhance the quality of the different illumination regions. Additionally, we develop a multi-dimensional low-light synthesis dataset (UDL) that includes more diverse illumination states in the real world and is larger than existing datasets. Extensive experiments on several benchmark datasets show that the proposed method is very competitive with state-of-the-art methods. Particularly when dealing with non-uniform low-light images, it has significant advantages in terms of illumination recovery and detail preservation.

![Fig 2](https://user-images.githubusercontent.com/66294411/196342227-d3aa9f4f-2754-4244-b412-2a23ae46a19c.png)

Anyone can access the UDL dataset via https://ln5.sync.com/dl/c51f8c480/uih7d8gc-zdbwhxvn-j8xah678-98k832ns
